{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, os.path\n",
    "path=\"weights\"\n",
    "num = 11\n",
    "\n",
    "weight_name = \"model_frcnn_\"+str(num)\n",
    "os.system(\n",
    "    \"python viz_frcnn.py\" + \n",
    "    \" -p data/2_sss_data/shoesSamples/forTest/\"+\n",
    "    \" --output_config_filename configs/\" + weight_name + \".pickle\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from optparse import OptionParser\n",
    "import time\n",
    "from keras_frcnn import config\n",
    "import keras_frcnn.resnet as nn\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import roi_helpers\n",
    "import random\n",
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "sys.setrecursionlimit(40000)\n",
    "\t\t\n",
    "# parser = OptionParser()\n",
    "\n",
    "# parser.add_option(\"-p\", \"--path\", dest=\"test_path\", help=\"Path to test data.\")\n",
    "# parser.add_option(\"-n\", \"--num_rois\", dest=\"num_rois\",\n",
    "# \t\t\t\thelp=\"Number of ROIs per iteration. Higher means more memory use.\", default=32)\n",
    "# parser.add_option(\"--output_config_filename\", dest=\"config_filename\", help=\n",
    "# \t\t\t\t\"Location to read the metadata related to the training (generated when training).\",\n",
    "# \t\t\t\tdefault=\"config.pickle\")\n",
    "# parser.add_option(\"--img_output\", dest=\"img_out_path\", help=\"Location to output the tested data images\") \n",
    "\n",
    "# (options, args) = parser.parse_args()\n",
    "# print((options, args))\n",
    "# if not options.test_path:   # if filename is not given\n",
    "# \tparser.error('Error: path to test data must be specified. Pass --path to command line')\n",
    "\n",
    "\n",
    "num = 11\n",
    "weight_name = \"model_frcnn_\"+str(num)\n",
    "\n",
    "config_output_filename =  \"configs/\" + weight_name + \".pickle\"\n",
    "\n",
    "\n",
    "with open(config_output_filename, 'r') as f_in:\n",
    "\tC = pickle.load(f_in)\n",
    "\n",
    "# turn off any data augmentation at test time\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "C.rot_90 = False\n",
    "\n",
    "img_path = \"data/2_sss_data/shoesSamples/forTest/\"\n",
    "\n",
    "\n",
    "def format_img(img, C):\n",
    "\timg_min_side = float(C.im_size)\n",
    "\t(height,width,_) = img.shape\n",
    "\t\n",
    "\tif width <= height:\n",
    "\t\tf = img_min_side/width\n",
    "\t\tnew_height = int(f * height)\n",
    "\t\tnew_width = int(img_min_side)\n",
    "\telse:\n",
    "\t\tf = img_min_side/height\n",
    "\t\tnew_width = int(f * width)\n",
    "\t\tnew_height = int(img_min_side)\n",
    "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\timg = img[:, :, (2, 1, 0)]\n",
    "\timg = img.astype(np.float32)\n",
    "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
    "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
    "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
    "\timg /= C.img_scaling_factor\n",
    "\timg = np.transpose(img, (2, 0, 1))\n",
    "\timg = np.expand_dims(img, axis=0)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "class_mapping = C.class_mapping\n",
    "\n",
    "if 'bg' not in class_mapping:\n",
    "\tclass_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "class_mapping = {v: k for k, v in class_mapping.iteritems()}\n",
    "print \"Class_mapping=\"\n",
    "print(class_mapping)\n",
    "\n",
    "colors ={ \t'shoe'\t :\t(0, 0,\t255), \n",
    "\t\t\t'slipper':\t(255,\t0,\t0),\n",
    "\t\t\t'sandal' :\t(0\t, 255,\t0),\n",
    "\t\t\t'bg'\t :\t(0\t,\t0,\t0)\n",
    "\t\t}\n",
    "\n",
    "class_to_color = {class_mapping[v]: colors[class_mapping[v]] for index, v in enumerate(class_mapping)}\n",
    "\n",
    "C.num_rois = int(options.num_rois)\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "\tinput_shape_features = (1024, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (None, None, 3)\n",
    "\tinput_shape_features = (None, None, 1024)\n",
    "\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(C.num_rois, 4))\n",
    "feature_map_input = Input(shape=input_shape_features)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn_layers = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "classifier = nn.classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(class_mapping), trainable=True)\n",
    "\n",
    "model_rpn = Model(img_input, rpn_layers)\n",
    "model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
    "\n",
    "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
    "\n",
    "model_rpn.load_weights(C.model_path, by_name=True)\n",
    "model_classifier.load_weights(C.model_path, by_name=True)\n",
    "\n",
    "model_rpn.compile(optimizer='sgd', loss='mse')\n",
    "model_classifier.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "\n",
    "# plot_model(model_classifier, to_file='model.png')  # outputed picture\n",
    "# print \"outputed\"\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model_classifier.layers])\n",
    "\n",
    "print layer_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
